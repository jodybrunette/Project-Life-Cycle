{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Recap\n",
    "\n",
    "Previously, we cleaned and prepared a dataset that contains data on loans made to members of [Lending Club](https://www.lendingclub.com/). Our goal is to generate features from the data, which can feed into a machine learning algorithm. This algorithm will make predictions about whether or not a loan will be paid off on time.\n",
    "\n",
    "As we prepared the data, we removed columns that had data leakage issues, contained redundant information, or required additional processing to turn into useful features. We cleaned features that had formatting issues, and converted categorical columns to dummy variables.\n",
    "\n",
    "Previously, we noticed that there's a class imbalance in our target column, `loan_status`. There are about 6 times as many loans that were paid off on time (positive case, label of 1) than those that weren't (negative case, label of 0). Imbalances can cause issues with many machine learning algorithms, where they appear to have high accuracy, but actually aren't learning from the training data. Because of its potential to cause issues, we need to keep the class imbalance in mind as we build machine learning models.\n",
    "\n",
    "After all of our data cleaning in the past two missions, we ended up with the csv file called cleaned_loans_2007.csv. Let's read this file into a Dataframe and view a summary of the work we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38708 entries, 0 to 38707\n",
      "Data columns (total 38 columns):\n",
      "loan_amnt                              38708 non-null float64\n",
      "int_rate                               38708 non-null float64\n",
      "installment                            38708 non-null float64\n",
      "emp_length                             38708 non-null int64\n",
      "annual_inc                             38708 non-null float64\n",
      "loan_status                            38708 non-null int64\n",
      "dti                                    38708 non-null float64\n",
      "delinq_2yrs                            38708 non-null float64\n",
      "inq_last_6mths                         38708 non-null float64\n",
      "open_acc                               38708 non-null float64\n",
      "pub_rec                                38708 non-null float64\n",
      "revol_bal                              38708 non-null float64\n",
      "revol_util                             38708 non-null float64\n",
      "total_acc                              38708 non-null float64\n",
      "home_ownership_MORTGAGE                38708 non-null float64\n",
      "home_ownership_NONE                    38708 non-null float64\n",
      "home_ownership_OTHER                   38708 non-null float64\n",
      "home_ownership_OWN                     38708 non-null float64\n",
      "home_ownership_RENT                    38708 non-null float64\n",
      "verification_status_Not Verified       38708 non-null float64\n",
      "verification_status_Source Verified    38708 non-null float64\n",
      "verification_status_Verified           38708 non-null float64\n",
      "purpose_car                            38708 non-null float64\n",
      "purpose_credit_card                    38708 non-null float64\n",
      "purpose_debt_consolidation             38708 non-null float64\n",
      "purpose_educational                    38708 non-null float64\n",
      "purpose_home_improvement               38708 non-null float64\n",
      "purpose_house                          38708 non-null float64\n",
      "purpose_major_purchase                 38708 non-null float64\n",
      "purpose_medical                        38708 non-null float64\n",
      "purpose_moving                         38708 non-null float64\n",
      "purpose_other                          38708 non-null float64\n",
      "purpose_renewable_energy               38708 non-null float64\n",
      "purpose_small_business                 38708 non-null float64\n",
      "purpose_vacation                       38708 non-null float64\n",
      "purpose_wedding                        38708 non-null float64\n",
      "term_ 36 months                        38708 non-null float64\n",
      "term_ 60 months                        38708 non-null float64\n",
      "dtypes: float64(36), int64(2)\n",
      "memory usage: 11.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loans = pd.read_csv('cleaned_loans_2007.csv')\n",
    "print(loans.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin with any machine learning, we will create a new DataFrame named features containing all of our feature columns and a new Series named target containing our target column so that we can use them across all of our modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = loans.columns\n",
    "feature_columns = cols.drop('loan_status')\n",
    "features = loans[feature_columns]\n",
    "target = loans['loan_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "### Choosing an Error Metric\n",
    "(source: Dataquest.io)\n",
    "An error metric will help us figure out whether our model is performing well. To tie error metrics to the project goal, we're using a machine learning model to predict whether or not we should fund a loan on the Lending Club platform. Our objective in this is to make money. We want to fund enough loans that are paid off on time to offset our losses from loans that aren't paid off. An error metric will help us determine if our algorithm will make us money or lose us money.\n",
    "\n",
    "In this case, we're primarily concerned with misclassifications of false positives and false negatives. With a false positive, we predict that a loan will be paid off on time, but it actually isn't. This costs us money, since we fund loans that lose us money. With a false negative, we predict that a loan won't be paid off on time, but it actually would be paid off on time. This loses us potential money, since we didn't fund a loan that actually would have been paid off.\n",
    "\n",
    "Since we're viewing this problem from the standpoint of a conservative investor, we need to treat false positives differently than false negatives. A conservative investor would want to minimize risk, and avoid false positives as much as possible. They'd be more okay with missing out on opportunities (false negatives) than they would be with funding a risky loan (false positives).\n",
    "\n",
    "We mentioned earlier that there is a significant class imbalance in the loan_status column. There are 6 times as many loans that were paid off on time (1), than loans that weren't paid off on time (0). This causes a major issue when we use accuracy as a metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    33093\n",
       "0     5615\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we don't want to use accuracy, and should instead use metrics that tell us the number of false positives and false negatives.\n",
    "\n",
    "This means that we should optimize for:\n",
    "\n",
    "- high recall (true positive rate)\n",
    "- low fall-out (false positive rate)\n",
    "\n",
    "We can think of the true positive rate as:\n",
    "- The percentage of the loans that should be funded that the model indicates to fund.\n",
    "We can think of the false positive rate as:\n",
    "- The percentage of the loans that shouldn't be funded that the model indicates to fund.\n",
    "\n",
    "We can calculate false positive rate and true positive rate, using the numbers of true positives, true negatives, false negatives, and false positives.\n",
    "\n",
    "### Logistic Regression Model\n",
    "A good first algorithm to apply to binary classification problems is logistic regression because:\n",
    "\n",
    "- it's quick to train and we can iterate more quickly,\n",
    "- it's less prone to overfitting than more complex models like decision trees,\n",
    "- it's easy to interpret.\n",
    "\n",
    "We will use K-Fold Cross Validation to help assess how the results of our model will generalize to an independent data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "lr = LogisticRegression(solver = 'liblinear')\n",
    "# Make predictions using 3-fold cross-validation.\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "# convert to a series for error metric evaluation\n",
    "predictions = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Error Metrics\n",
    "Calculating false positive rate and true positive rates for our logistic regression predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr: 0.9989121566494424\n",
      "fpr: 0.9967943009795192\n"
     ]
    }
   ],
   "source": [
    "tn_filter = (predictions == 0) & (target == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "tp_filter = (predictions == 1) & (target == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "fn_filter = (predictions == 0) & (target == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "fp_filter = (predictions == 1) & (target == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "tpr = tp/(tp + fn)\n",
    "fpr = fp/(fp + tn)\n",
    "print('tpr:', tpr)\n",
    "print('fpr:', fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These rates indicate that we correctly identified all of the good loans (true positive rate) 99.8% of the time, but we also incorrectly identified all of the bad loans (false positive rate) 99.8% of the time. Even through we're not using accuracy as an error metric, the classifier is, and it isn't accounting for the imbalance in the classes.\n",
    "\n",
    "To help combat this class imbalance we can tell the classifier to penalize misclassifications of the less prevalent class more than the other class. The penalty means that the logistic regression classifier pays more attention to correctly classifying rows where `loan_status` is `0`. This lowers accuracy when `loan_status` is `1`, but raises accuracy when `loan_status` is `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr: 0.6579034841205089\n",
      "fpr: 0.38290293855743546\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear', class_weight = 'balanced')\n",
    "predictions = cross_val_predict(lr, features, target, cv = 3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tn_filter = (predictions == 0) & (target == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "tp_filter = (predictions == 1) & (target == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "fn_filter = (predictions == 0) & (target == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "fp_filter = (predictions == 1) & (target == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "tpr = tp/(tp + fn)\n",
    "fpr = fp/(fp + tn)\n",
    "print('tpr:', tpr)\n",
    "print('fpr:', fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to  improve the false positive rate by balancing the classes, which also reduced true positive rate. Our true positive rate is now around 66%, and our false positive rate is around 38%. \n",
    "\n",
    "From a conservative investor's standpoint, it's reassuring that the false positive rate is lower because it means that we'll be able to do a better job at avoiding bad loans than if we funded everything. However, we'd only ever decide to fund 66% of the total available loans (true positive rate), so we'd be immediately rejecting a good amount of loans.\n",
    "\n",
    "Let's try to lower the false positive rate further by assigning a harsher penalty (10 insteat of the approximate 6 times we tested above) for misclassifying the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr: 0.24005076602302602\n",
      "fpr: 0.09029385574354408\n"
     ]
    }
   ],
   "source": [
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(solver = 'liblinear', class_weight = penalty)\n",
    "predictions = cross_val_predict(lr, features, target, cv = 3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tn_filter = (predictions == 0) & (target == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "tp_filter = (predictions == 1) & (target == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "fn_filter = (predictions == 0) & (target == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "fp_filter = (predictions == 1) & (target == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "tpr = tp/(tp + fn)\n",
    "fpr = fp/(fp + tn)\n",
    "print('tpr:', tpr)\n",
    "print('fpr:', fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like manually assigining the harsher penalties lowered the false positive rate to 9%, lowering our risk. However, note that this comes at the expense of true positive rate which dropped to 24%. While we have fewer false positives, we're also missing opportunities to fund more loans and potentially make more money. \n",
    "\n",
    "Given that we're approaching this as a conservative investor, this strategy seems to make sense, but it's worth keeping in mind the tradeoffs we have taken.\n",
    "\n",
    "### Random Forest Model\n",
    "Next, let's try a more complex algorithm, the random forest. Random forests are able to work with nonlinear data and learn complex conditionals. Logistic regressions are only able to work with linear data. Training a random forest algorithm may enable us to get more accuracy due to columns that correlate nonlinearly with 'loan_status'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr: 0.9977034418154896\n",
      "fpr: 0.9894924309884239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 1, class_weight = 'balanced', n_estimators = 100)\n",
    "predictions = cross_val_predict(rf, features, target, cv = 3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tn_filter = (predictions == 0) & (target == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "tp_filter = (predictions == 1) & (target == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "fn_filter = (predictions == 0) & (target == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "fp_filter = (predictions == 1) & (target == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "tpr = tp/(tp + fn)\n",
    "fpr = fp/(fp + tn)\n",
    "print('tpr:', tpr)\n",
    "print('fpr:', fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, using a random forest classifier didn't improve our false positive rate. The model is likely weighting too heavily on the `1` class, and still mostly predicting 1s. We could try to fix this by applying a harsher penalty for misclassifications of `0`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr: 0.997975402653129\n",
      "fpr: 0.9926981300089047\n"
     ]
    }
   ],
   "source": [
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "rf = RandomForestClassifier(random_state = 1, class_weight = penalty, n_estimators = 100)\n",
    "predictions = cross_val_predict(rf, features, target, cv = 3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tn_filter = (predictions == 0) & (target == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "tp_filter = (predictions == 1) & (target == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "fn_filter = (predictions == 0) & (target == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "fp_filter = (predictions == 1) & (target == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "tpr = tp/(tp + fn)\n",
    "fpr = fp/(fp + tn)\n",
    "print('tpr:', tpr)\n",
    "print('fpr:', fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting the penalties didn't seem to help at all.\n",
    "We can try to tweak some of the parameters of the model to see if any improvement is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr: 0.7135345843531865\n",
      "fpr: 0.44968833481745324\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 1, class_weight = 'balanced', n_estimators = 150, min_samples_leaf = 50, max_features = 'log2', )\n",
    "predictions = cross_val_predict(rf, features, target, cv = 3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tn_filter = (predictions == 0) & (target == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "tp_filter = (predictions == 1) & (target == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "fn_filter = (predictions == 0) & (target == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "fp_filter = (predictions == 1) & (target == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "tpr = tp/(tp + fn)\n",
    "fpr = fp/(fp + tn)\n",
    "print('tpr:', tpr)\n",
    "print('fpr:', fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, tweaking some parameters of the random forest model only imporved out model to a false positive rate of 44% and a true positive rate of 71%.  This model doesn't perform as well for the conservative investor as the logistic regression model has. \n",
    "\n",
    "Let's try another approach.\n",
    "\n",
    "## Neural Network Model\n",
    "A neural network model is a type of model that exels at capturing nonlinear relationships in data. We will start with the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr: 0.7676850089142719\n",
      "fpr: 0.6432769367764916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state = 1)\n",
    "predictions = cross_val_predict(mlp, features, target, cv = 3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tn_filter = (predictions == 0) & (target == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "tp_filter = (predictions == 1) & (target == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "fn_filter = (predictions == 0) & (target == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "fp_filter = (predictions == 1) & (target == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "tpr = tp/(tp + fn)\n",
    "fpr = fp/(fp + tn)\n",
    "print('tpr:', tpr)\n",
    "print('fpr:', fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr: 0.6405282083824374\n",
      "fpr: 0.6094390026714158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp2 = MLPClassifier(random_state = 1, hidden_layer_sizes = (10,))\n",
    "predictions = cross_val_predict(mlp2, features, target, cv = 3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tn_filter = (predictions == 0) & (target == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "tp_filter = (predictions == 1) & (target == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "fn_filter = (predictions == 0) & (target == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "fp_filter = (predictions == 1) & (target == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "tpr = tp/(tp + fn)\n",
    "fpr = fp/(fp + tn)\n",
    "print('tpr:', tpr)\n",
    "print('fpr:', fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreasing the `hidden_layer_sizes` (or a few other parameters) didn't improve our false positive rate to anywhere near the 9% in the logistic regression model. This is the metric we want to reduce as a conservative investor.\n",
    "\n",
    "Ultimately, our best model had a false positive rate of 9%, and a true positive rate of 24%. For a conservative investor, this means that they make money as long as the interest rate is high enough to offset the losses from 9% of borrowers defaulting, and that the pool of 24% of borrowers is large enough to make enough interest money to offset the losses.\n",
    "\n",
    "## Next Steps\n",
    "If we had randomly picked loans to fund, borrowers would have defaulted on 14.5% of them, and our model logistic regression is better than that, although we're excluding more loans than a random strategy would. Given this, there's still quite a bit of room to improve:\n",
    "\n",
    "- We can tweak the penalties further.\n",
    "- We can try models other than a random forest and logistic regression.\n",
    "- We can use some of the columns we discarded to generate better features.\n",
    "- We can ensemble multiple models to get more accurate predictions.\n",
    "- We can tune the parameters of the algorithm to achieve higher performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
